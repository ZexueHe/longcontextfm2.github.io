---
layout: page
title: home
permalink: /
title: Instruction Tuning and Instruction Following
description: Workshop Proposal for NeurIPS 2023

---

___Natural language instructions are the new programming languages! ... Are they? :thinking:___


<br>

## Overview

Recent advancements in training large language models (LLMs) to follow "instructions" have significantly increased their ability to comprehend open-ended language commands, encompassing a wide range of needs, preferences, and values.

This remarkable transformation has led to the creation of phenomenal industrial models such as [GPT-4](https://arxiv.org/abs/2303.08774) and [Bard](https://blog.google/technology/ai/bard-google-ai-search-updates/), as well as an increased focus within the open-source and research communities: creating new benchmark and resources [[1](https://aclanthology.org/2022.emnlp-main.340/),[2](https://arxiv.org/abs/2301.13688)], developing new training methods [[3](https://arxiv.org/abs/2203.02155),[4](https://arxiv.org/abs/2212.10560)], and understanding the limitations of these methods [[5](https://arxiv.org/abs/2109.01247)]. Furthermore, instruction following powered by LLMs has proven to be effective in multi-modal settings, with applications in image editing [[6](https://arxiv.org/abs/2211.09800)] and robotic command execution [[7](https://arxiv.org/abs/2204.01691)].

We propose to organize this workshop to facilitate discussions on __advancing instruction tuning methodologies and constructing general-purpose instruction-following models__. We believe it is crucial to convene this workshop due to the prevalence of proprietary models with restricted access, thereby creating the need for an open platform to encourage transparent discussions. Moreover, we aim to foster interdisciplinary collaboration by bringing together researchers from diverse fields such as natural language processing, computer vision, robotics, human-computer interaction, AI safety, among others, to share their latest findings and explore potential avenues for future research.

__Centering on "instructions"__, we encourage submissions on the following topics:

* __Modeling:__ algorithms and pipelines for learning from instructions, human feedback, and human intent; designing training objectives and rewards; evaluation framework; training and inference efficiency
* __Data Curation:__ crowd-sourcing; synthetic data generation; data democratization
* __Empirical Analysis:__ effective and holistic evaluation; failure cases; frontier problems; controlled probing; model interpretability
* __Engineering and Open-sourcing:__ best practice in training, evaluation and deployment; open-sourcing efforts; openness and reproducibility
* __Applications:__ long-context, multi-round and personalized instruction-following models
* __Limitations, Risks and Safety:__ calibration, fairness, bias, factuality, scalable oversight
* Other adjacent research topics (e.g., in-context learning, prompting, multi-task learning, multi-modal learning) that enable better responses to instructions in dynamic environments.

<br>

## Speakers

* [Hannaneh Hajishirzi](https://homes.cs.washington.edu/~hannaneh/), University of Washington, Allen AI
* [Nazneen Rajani](https://www.cs.princeton.edu/~danqic/), Hugging Face
* [Sam Bowman](https://cims.nyu.edu/~sbowman/), Anthorpic, New York University
* [Xipeng Qiu](https://xpqiu.github.io/en.html), Fudan University
* [Omer Levy](https://www.cs.tau.ac.il/~levyomer/), Tel Aviv University, Meta AI

<br>

## Organizers

* [Qinyuan Ye](http://yeqy.xyz/), University of Southern California
* [Yizhong Wang](https://homes.cs.washington.edu/~yizhongw/), University of Washington
* [Shayne Longpre](https://www.shaynelongpre.com/), Massachusetts Institute of Technology
* [Yao Fu](https://franxyao.github.io/), University of Edinburgh
* [Daniel Khashabi](https://danielkhashabi.com/), Johns Hopkins University

<br>

## Contact Us
Email: [an-instructive-workshop@googlegroups.com](mailto:an-instructive-workshop@googlegroups.com)